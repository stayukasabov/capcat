<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>core.article_fetcher</title>
    <link rel="stylesheet" href="../../../css/design-system.css">
    <link rel="stylesheet" href="../../../css/main.css">
</head>
<body>
    <!-- Header -->
    <div id="header-placeholder"></div>


    <div class="doc-container">
        <div class="container">
            <div class="doc-content">

<div class="nav-breadcrumb"><a href="../../index.html">Documentation Home</a> / <a href="../index.html">api</a> / core</div>
<h1>core.article_fetcher</h1>

<h4>File:</h4> <code>Application/core/article_fetcher.py</code>

<h2>Description</h2>

<p>Shared article fetching functionality for Capcat sources.</p>

<p>This module contains the base ArticleFetcher class that eliminates</p>
<p>code duplication between source-specific implementations.</p>

<h2>Constants</h2>

<h3>_GLOBAL_UPDATE_MODE</h3>

<h4>Value:</h4> <code>False</code>

<h3>_GLOBAL_UPDATE_MODE</h3>

<h4>Value:</h4> <code>update_mode</code>

<h2>Classes</h2>

<h3>ArticleFetcher</h3>

<h4>Inherits from:</h4> ABC

<p>Base class for article fetching with shared functionality.</p>

<p>This eliminates code duplication between HN and Lobsters implementations</p>
<p>while allowing source-specific customizations.</p>

<h3>Methods</h3>

<h5>__init__</h5>

<pre><code>def __init__(self, session: requests.Session, download_files: bool = False, source_code: str = &#x27;unknown&#x27;)
</code></pre>

<p>Initialize with a requests session for connection pooling.</p>

<p>Args:</p>
<p>    session: Requests session for connection pooling</p>
<p>    download_files: Whether to download all media files</p>
<p>    source_code: Source identifier for rate limiting</p>
<p>        (e.g., &#x27;hn&#x27;, &#x27;scientificamerican&#x27;)</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>session</code> (requests.Session)</li>
<li><code>download_files</code> (bool) <em>optional</em></li>
<li><code>source_code</code> (str) <em>optional</em></li>
</ul>

<h5>set_download_files</h5>

<pre><code>def set_download_files(self, download_files: bool)
</code></pre>

<p>Dynamically set the download_files flag.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>download_files</code> (bool)</li>
</ul>

<h5>_create_markdown_link_replacement</h5>

<pre><code>def _create_markdown_link_replacement(self, markdown_content: str, original_url: str, local_path: str, fallback_text: str, is_image: bool = False) -&gt; str
</code></pre>

<p>Replace markdown link/image references with local paths.</p>

<p>Consolidates duplicate URL replacement logic that appears 4+ times</p>
<p>in the codebase. Handles both image and link syntax with proper</p>
<p>f-string formatting to prevent syntax errors.</p>

<p>Args:</p>
<p>    markdown_content: Markdown text to process</p>
<p>    original_url: URL to replace (will be escaped for regex)</p>
<p>    local_path: Local file path to use instead</p>
<p>    fallback_text: Text to use if link text is empty</p>
<p>    is_image: True for image syntax (![]()),</p>
<p>        False for link syntax ([])</p>

<p>Returns:</p>
<p>    Updated markdown content with replaced URLs</p>

<p>Example:</p>
<p>    &gt;&gt;&gt; content = &quot;![](http://example.com/img.jpg)&quot;</p>
<p>    &gt;&gt;&gt; result = self._create_markdown_link_replacement(</p>
<p>    ...     content, &quot;http://example.com/img.jpg&quot;,</p>
<p>    ...     &quot;images/img.jpg&quot;, &quot;image&quot;, is_image=True</p>
<p>    ... )</p>
<p>    &gt;&gt;&gt; print(result)</p>
<p>    !<a href="images/img.jpg">image</a></p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>markdown_content</code> (str)</li>
<li><code>original_url</code> (str)</li>
<li><code>local_path</code> (str)</li>
<li><code>fallback_text</code> (str)</li>
<li><code>is_image</code> (bool) <em>optional</em></li>
</ul>

<h4>Returns:</h4> str

<h5>_fetch_url_with_retry</h5>

<pre><code>def _fetch_url_with_retry(self, url: str, timeout: int = None) -&gt; requests.Response
</code></pre>

<p>Fetch URL with automatic retry logic, rate limiting, and</p>
<p>adaptive timeouts.</p>

<p>This method provides:</p>
<ul>
<li>Adaptive timeouts based on source performance</li>
<li>Rate limiting based on source-specific configuration</li>
<li>Up to 3 retry attempts (via @network_retry decorator)</li>
<li>Exponential backoff (1s, 2s, 4s)</li>
<li>Automatic handling of connection errors and timeouts</li>
<li>Response time tracking for adaptive learning</li>
</ul>

<p>Args:</p>
<p>    url: URL to fetch</p>
<p>    timeout: Optional timeout override (uses adaptive if None)</p>

<p>Returns:</p>
<p>    Response object</p>

<p>Raises:</p>
<p>    requests.exceptions.RequestException: After all retries exhausted</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>url</code> (str)</li>
<li><code>timeout</code> (int) <em>optional</em></li>
</ul>

<h4>Returns:</h4> requests.Response

<h5>should_skip_url</h5>

<pre><code>def should_skip_url(self, url: str, title: str) -&gt; bool
</code></pre>

<p>Source-specific logic to determine if a URL should be skipped.</p>

<p>Args:</p>
<p>    url: The article URL to check</p>
<p>    title: The article title</p>

<p>Returns:</p>
<p>    True if the URL should be skipped, False otherwise</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>url</code> (str)</li>
<li><code>title</code> (str)</li>
</ul>

<h4>Returns:</h4> bool

<h5>fetch_article_content</h5>

<pre><code>def fetch_article_content(self, title: str, url: str, index: int, base_folder: str, progress_callback: Optional[Callable[[float, str], None]] = None) -&gt; Tuple[bool, Optional[str], Optional[str]]
</code></pre>

<p>Fetch and save the content of an article in markdown format.</p>

<p>This method handles ONLY article content fetching. Comments should be</p>
<p>fetched separately using source-specific comment fetching methods.</p>

<p>Args:</p>
<p>    title: Article title</p>
<p>    url: Article URL</p>
<p>    index: Article index number</p>
<p>    base_folder: Base directory to save to</p>
<p>    progress_callback: Optional callback function for progress</p>
<p>        updates (progress, stage)</p>

<p>Returns:</p>
<p>    Tuple[bool, Optional[str], Optional[str]]: (success,</p>
<p>        article_folder_path, article_title)</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>title</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>index</code> (int)</li>
<li><code>base_folder</code> (str)</li>
<li><code>progress_callback</code> (Optional[Callable[[float, str], None]]) <em>optional</em></li>
</ul>

<h4>Returns:</h4> Tuple[bool, Optional[str], Optional[str]]

<p>WARNING: <h4>High complexity:</h4> 11</p>

<h5>_is_pdf_url</h5>

<pre><code>def _is_pdf_url(self, url: str) -&gt; bool
</code></pre>

<p>Check if a URL points specifically to a PDF file.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>url</code> (str)</li>
</ul>

<h4>Returns:</h4> bool

<h5>_handle_media_file</h5>

<pre><code>def _handle_media_file(self, title: str, url: str, index: int, base_folder: str, file_type: str) -&gt; Tuple[bool, Optional[str], Optional[str]]
</code></pre>

<p>Handle direct media file downloads (documents, audio, video, PDF).</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>title</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>index</code> (int)</li>
<li><code>base_folder</code> (str)</li>
<li><code>file_type</code> (str)</li>
</ul>

<h4>Returns:</h4> Tuple[bool, Optional[str], Optional[str]]

<h5>_fetch_web_content</h5>

<pre><code>def _fetch_web_content(self, title: str, url: str, index: int, base_folder: str, progress_callback: Optional[Callable[[float, str], None]] = None) -&gt; Tuple[bool, Optional[str], Optional[str]]
</code></pre>

<p>Fetch and process regular web page content.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>title</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>index</code> (int)</li>
<li><code>base_folder</code> (str)</li>
<li><code>progress_callback</code> (Optional[Callable[[float, str], None]]) <em>optional</em></li>
</ul>

<h4>Returns:</h4> Tuple[bool, Optional[str], Optional[str]]

<p>WARNING: <h4>High complexity:</h4> 61</p>

<h5>_cleanup_empty_images_folder</h5>

<pre><code>def _cleanup_empty_images_folder(self, article_folder_path: str) -&gt; None
</code></pre>

<p>Remove images folder if it exists but is empty.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>article_folder_path</code> (str)</li>
</ul>

<h4>Returns:</h4> None

<h5>_parse_srcset</h5>

<pre><code>def _parse_srcset(self, srcset: str) -&gt; str
</code></pre>

<p>Parse srcset attribute and return the highest resolution image URL.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>srcset</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<h5>_remove_image_from_markdown</h5>

<pre><code>def _remove_image_from_markdown(self, markdown_content: str, image_src: str) -&gt; str
</code></pre>

<p>Remove image references from markdown content when download fails.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>markdown_content</code> (str)</li>
<li><code>image_src</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<h5>_process_document_links</h5>

<pre><code>def _process_document_links(self, soup: BeautifulSoup, markdown_content: str, article_folder_path: str, base_url: str) -&gt; str
</code></pre>

<p>Process and download document files linked in the content.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>soup</code> (BeautifulSoup)</li>
<li><code>markdown_content</code> (str)</li>
<li><code>article_folder_path</code> (str)</li>
<li><code>base_url</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<p>WARNING: <h4>High complexity:</h4> 14</p>

<h5>_process_embedded_media_efficiently</h5>

<pre><code>def _process_embedded_media_efficiently(self, soup: BeautifulSoup, markdown_content: str, article_folder_path: str, base_url: str) -&gt; str
</code></pre>

<p>Process and download embedded media files efficiently with batch</p>
<p>processing.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>soup</code> (BeautifulSoup)</li>
<li><code>markdown_content</code> (str)</li>
<li><code>article_folder_path</code> (str)</li>
<li><code>base_url</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<p>WARNING: <h4>High complexity:</h4> 90</p>

<h5>_fallback_image_detection</h5>

<pre><code>def _fallback_image_detection(self, full_page_html: str, existing_images: set, article_folder_path: str, base_url: str) -&gt; List[str]
</code></pre>

<p>Fallback image detection system that scans the entire page for images</p>
<p>when the primary extraction method finds few images.</p>

<p>Args:</p>
<p>    full_page_html: Original full page HTML before article extraction</p>
<p>    existing_images: Set of image URLs already found by primary method</p>
<p>    article_folder_path: Path to save downloaded images</p>
<p>    base_url: Base URL for resolving relative image paths</p>

<p>Returns:</p>
<p>    List of additional image URLs found and downloaded</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>full_page_html</code> (str)</li>
<li><code>existing_images</code> (set)</li>
<li><code>article_folder_path</code> (str)</li>
<li><code>base_url</code> (str)</li>
</ul>

<h4>Returns:</h4> List[str]

<p>WARNING: <h4>High complexity:</h4> 19</p>

<h5>_should_skip_image</h5>

<pre><code>def _should_skip_image(self, img_tag, img_src: str, ui_patterns: dict) -&gt; bool
</code></pre>

<p>Determine if an image should be skipped based on UI element patterns.</p>

<p>Args:</p>
<p>    img_tag: BeautifulSoup img tag</p>
<p>    img_src: Image source URL</p>
<p>    ui_patterns: Dictionary of patterns to match against</p>

<p>Returns:</p>
<p>    True if image should be skipped (is likely a UI element)</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>img_tag</code></li>
<li><code>img_src</code> (str)</li>
<li><code>ui_patterns</code> (dict)</li>
</ul>

<h4>Returns:</h4> bool

<p>WARNING: <h4>High complexity:</h4> 11</p>

<h5>_cleanup_failed_media_reference</h5>

<pre><code>def _cleanup_failed_media_reference(self, markdown_content: str, url: str, link_type: str, alt_text: str) -&gt; str
</code></pre>

<p>Clean up broken media references when download fails.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>markdown_content</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>link_type</code> (str)</li>
<li><code>alt_text</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<h5>_get_next_available_index</h5>

<pre><code>def _get_next_available_index(self, base_folder: str, suggested_index: int) -&gt; int
</code></pre>

<p>Get the next available index to avoid duplicate folder numbering.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>base_folder</code> (str)</li>
<li><code>suggested_index</code> (int)</li>
</ul>

<h4>Returns:</h4> int

<h5>_get_unique_folder_name</h5>

<pre><code>def _get_unique_folder_name(self, base_folder: str, base_title: str) -&gt; str
</code></pre>

<p>Get folder name - always returns base_title to allow overwrite.</p>
<p>When user runs repeatedly, content is replaced instead of</p>
<p>creating duplicates.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>base_folder</code> (str)</li>
<li><code>base_title</code> (str)</li>
</ul>

<h4>Returns:</h4> str

<h5>_discover_rss_feed</h5>

<pre><code>def _discover_rss_feed(self, base_url: str) -&gt; Optional[str]
</code></pre>

<p>Attempt to discover RSS/Atom feed for a website.</p>

<p>Args:</p>
<p>    base_url: Base URL of the website</p>

<p>Returns:</p>
<p>    Feed URL if found, None otherwise</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>base_url</code> (str)</li>
</ul>

<h4>Returns:</h4> Optional[str]

<h5>_create_error_article</h5>

<pre><code>def _create_error_article(self, title: str, url: str, error_type: str, error_details: str, base_folder: str, rss_feed_url: Optional[str] = None) -&gt; Tuple[bool, Optional[str], Optional[str]]
</code></pre>

<p>Create a clean error article when fetching fails.</p>

<p>Args:</p>
<p>    title: Article title</p>
<p>    url: Original article URL</p>
<p>    error_type: Type of error (e.g., &quot;403 Forbidden&quot;,</p>
<p>        &quot;Connection Timeout&quot;)</p>
<p>    error_details: Detailed error message</p>
<p>    base_folder: Base directory to save to</p>
<p>    rss_feed_url: Optional RSS feed URL if discovered</p>

<p>Returns:</p>
<p>    Tuple[bool, Optional[str], Optional[str]]: (success,</p>
<p>        article_title, article_folder_path)</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>title</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>error_type</code> (str)</li>
<li><code>error_details</code> (str)</li>
<li><code>base_folder</code> (str)</li>
<li><code>rss_feed_url</code> (Optional[str]) <em>optional</em></li>
</ul>

<h4>Returns:</h4> Tuple[bool, Optional[str], Optional[str]]

<h3>HackerNewsArticleFetcher</h3>

<h4>Inherits from:</h4> ArticleFetcher

<p>Hacker News specific article fetcher.</p>

<h3>Methods</h3>

<h5>__init__</h5>

<pre><code>def __init__(self, session, download_files: bool = False)
</code></pre>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>session</code></li>
<li><code>download_files</code> (bool) <em>optional</em></li>
</ul>

<h5>should_skip_url</h5>

<pre><code>def should_skip_url(self, url: str, title: str) -&gt; bool
</code></pre>

<p>Skip Hacker News internal links.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>url</code> (str)</li>
<li><code>title</code> (str)</li>
</ul>

<h4>Returns:</h4> bool

<h3>LobstersArticleFetcher</h3>

<h4>Inherits from:</h4> ArticleFetcher

<p>Lobsters specific article fetcher.</p>

<h3>Methods</h3>

<h5>__init__</h5>

<pre><code>def __init__(self, session, download_files: bool = False)
</code></pre>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>session</code></li>
<li><code>download_files</code> (bool) <em>optional</em></li>
</ul>

<h5>should_skip_url</h5>

<pre><code>def should_skip_url(self, url: str, title: str) -&gt; bool
</code></pre>

<p>Skip Lobste.rs internal links that don&#x27;t point to external content.</p>

<h4>Parameters:</h4>

<ul>
<li><code>self</code></li>
<li><code>url</code> (str)</li>
<li><code>title</code> (str)</li>
</ul>

<h4>Returns:</h4> bool

<h2>Functions</h2>

<h3>set_global_update_mode</h3>

<pre><code>def set_global_update_mode(update_mode: bool)
</code></pre>

<p>Set the global update mode flag.</p>

<h4>Parameters:</h4>

<ul>
<li><code>update_mode</code> (bool)</li>
</ul>

<h3>get_global_update_mode</h3>

<pre><code>def get_global_update_mode() -&gt; bool
</code></pre>

<p>Get the global update mode flag.</p>

<h4>Returns:</h4> bool

<h3>convert_html_with_timeout</h3>

<pre><code>def convert_html_with_timeout(html_content: str, url: str, timeout: int = CONVERSION_TIMEOUT_SECONDS) -&gt; str
</code></pre>

<p>Convert HTML to markdown with thread-safe timeout protection.</p>

<p>Uses concurrent.futures for thread-safe timeout handling, replacing</p>
<p>signal-based approach which caused race conditions in parallel processing.</p>

<p>Args:</p>
<p>    html_content: Raw HTML content to convert</p>
<p>    url: Source URL for logging context</p>
<p>    timeout: Maximum seconds to allow conversion (default: 30)</p>

<p>Returns:</p>
<p>    Converted markdown content, empty string if timeout or error</p>

<p>Raises:</p>
<p>    None - All exceptions are caught and logged</p>

<p>Example:</p>
<p>    &gt;&gt;&gt; html = &quot;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Test&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;&quot;</p>
<p>    &gt;&gt;&gt; markdown = convert_html_with_timeout(html, &quot;https://example.com&quot;)</p>
<p>    &gt;&gt;&gt; print(markdown)</p>
<p>    # Test</p>

<p>Thread Safety:</p>
<p>    This function is thread-safe and can be called concurrently</p>
<p>    from multiple threads without race conditions.</p>

<h4>Parameters:</h4>

<ul>
<li><code>html_content</code> (str)</li>
<li><code>url</code> (str)</li>
<li><code>timeout</code> (int) <em>optional</em></li>
</ul>

<h4>Returns:</h4> str

<h3>replacement_func</h3>

<pre><code>def replacement_func(match)
</code></pre>

<p>Create replacement text with fallback for empty groups.</p>

<h4>Parameters:</h4>

<ul>
<li><code>match</code></li>
</ul>

<h3>replace_if_image_link</h3>

<pre><code>def replace_if_image_link(match)
</code></pre>

<h4>Parameters:</h4>

<ul>
<li><code>match</code></li>
</ul>

<h3>process_single_media</h3>

<pre><code>def process_single_media(link_info)
</code></pre>

<h4>Parameters:</h4>

<ul>
<li><code>link_info</code></li>
</ul>


<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({
    startOnLoad: true,
    theme: 'base',
    themeVariables: {
      // Primary colors from design system (Capcat orange palette)
      primaryColor: '#FFD4B7',           // --orange-200
      primaryTextColor: '#201419',       // --ink
      primaryBorderColor: '#F1540E',     // --orange-500 / --accent-primary

      // Line and edge colors
      lineColor: '#58444c',              // --ink-medium

      // Secondary colors
      secondaryColor: '#FFEADB',         // --orange-100
      tertiaryColor: '#f9f8ed',          // --accent-cream-primary

      // Text colors
      textColor: '#201419',              // --ink
      mainBkg: '#FAF8EE',                // --cream

      // Node styling
      nodeBorder: '#F1540E',             // --accent-primary
      clusterBkg: '#faf2e7',             // --accent-cream-light
      clusterBorder: '#D44400',          // --orange-600 / --accent-hover

      // Font
      fontFamily: '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif',
      fontSize: '16px'
    },
    flowchart: {
      nodeSpacing: 50,
      rankSpacing: 50,
      padding: 15,
      useMaxWidth: true,
      htmlLabels: true,
      curve: 'basis'
    }
  });

  // Add copy buttons to Mermaid diagrams after rendering
  document.addEventListener('DOMContentLoaded', function() {
    const mermaidDivs = document.querySelectorAll('.mermaid');

    mermaidDivs.forEach(function(mermaidDiv) {
      // Get the original Mermaid source code
      const mermaidSource = mermaidDiv.textContent;

      // Create container wrapper
      const container = document.createElement('div');
      container.className = 'mermaid-container';

      // Create copy button
      const copyBtn = document.createElement('button');
      copyBtn.className = 'mermaid-copy-btn';
      copyBtn.textContent = 'Copy Mermaid Code';
      copyBtn.setAttribute('title', 'Copy diagram code for Draw.io, Mermaid Live, etc.');

      copyBtn.addEventListener('click', function() {
        navigator.clipboard.writeText(mermaidSource).then(function() {
          copyBtn.textContent = 'Copied!';
          copyBtn.classList.add('copied');

          setTimeout(function() {
            copyBtn.textContent = 'Copy Mermaid Code';
            copyBtn.classList.remove('copied');
          }, 2000);
        });
      });

      // Wrap the mermaid div in container and add button
      mermaidDiv.parentNode.insertBefore(container, mermaidDiv);
      container.appendChild(mermaidDiv);
      container.appendChild(copyBtn);
    });
  });
</script>
    <script src="../../../js/main.js"></script>

            </div>
        </div>
    </div>

    <!-- Footer -->
    <div id="footer-placeholder"></div>

    <!-- Back to Top Button -->
    <button id="backToTopBtn" title="Go to top">
        <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" width="24">
            <path d="M0 0h24v24H0V0z" fill="none"/>
            <path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6 1.41 1.41z"/>
        </svg>
    </button>

    <script src="../../../../js/includes-loader.js"></script>
  </body>
