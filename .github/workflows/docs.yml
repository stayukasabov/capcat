name: Generate Documentation

on:
  push:
    branches: [main, develop]
    paths:
      - 'core/**'
      - 'sources/**'
      - 'cli.py'
      - 'capcat.py'
      - 'scripts/doc_generator.py'
      - 'scripts/generate_diagrams.py'
  pull_request:
    branches: [main]
    paths:
      - 'core/**'
      - 'sources/**'
      - 'cli.py'
      - 'capcat.py'
  workflow_dispatch:
    inputs:
      force_rebuild:
        description: 'Force complete documentation rebuild'
        required: false
        default: 'false'

jobs:
  generate-docs:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for better analysis

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt || echo "requirements-dev.txt not found, skipping"

        # Install documentation tools
        pip install sphinx sphinx-rtd-theme myst-parser
        pip install pydocstyle pylint bandit safety

    - name: Create scripts directory if not exists
      run: mkdir -p scripts

    - name: Lint and validate code
      run: |
        # Code quality checks
        echo "Running code quality checks..."
        python -m pylint core/ sources/ capcat.py cli.py --exit-zero --output-format=text --reports=no > docs_lint_report.txt || true

        # Security scan
        echo "Running security scan..."
        bandit -r core/ sources/ capcat.py cli.py -f txt -o docs_security_report.txt || true

        # Dependency security check
        echo "Checking dependency security..."
        safety check --output=text > docs_safety_report.txt || true

    - name: Generate code documentation
      run: |
        echo "Generating API documentation..."
        python scripts/doc_generator.py

        echo "Documentation generation completed"

    - name: Generate architecture diagrams
      run: |
        echo "Generating architecture diagrams..."
        python scripts/generate_diagrams.py

        echo "Diagram generation completed"

    - name: Generate coverage report
      run: |
        echo "Generating test coverage report..."
        # Run tests with coverage if test files exist
        if [ -d "tests" ] || find . -name "test_*.py" | grep -q .; then
          python -m pytest --cov=core --cov=sources --cov-report=html --cov-report=term > docs_coverage_report.txt || true
          # Move coverage HTML to docs
          if [ -d "htmlcov" ]; then
            mv htmlcov docs/coverage/
          fi
        else
          echo "No tests found, skipping coverage report"
        fi

    - name: Generate documentation statistics
      run: |
        echo "Generating documentation statistics..."
        python -c "
import os
import json
from pathlib import Path

def count_files(directory, extension):
    return len(list(Path(directory).rglob(f'*.{extension}')))

def get_file_size(directory):
    total_size = 0
    for root, dirs, files in os.walk(directory):
        for file in files:
            total_size += os.path.getsize(os.path.join(root, file))
    return total_size

stats = {
    'python_files': count_files('.', 'py'),
    'markdown_files': count_files('docs', 'md'),
    'total_lines': 0,
    'documentation_size_mb': round(get_file_size('docs') / (1024*1024), 2),
    'generation_timestamp': '$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")'
}

# Count lines of code
for py_file in Path('.').rglob('*.py'):
    if 'venv' not in str(py_file) and '__pycache__' not in str(py_file):
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                stats['total_lines'] += len(f.readlines())
        except:
            pass

with open('docs/stats.json', 'w') as f:
    json.dump(stats, f, indent=2)

print(f'Documentation statistics generated: {stats}')
        "

    - name: Validate documentation
      run: |
        echo "Validating generated documentation..."

        # Check if essential files were generated
        required_files=(
          "docs/README.md"
          "docs/index.md"
          "docs/api/README.md"
          "docs/architecture/system.md"
          "docs/developer/guide.md"
        )

        for file in "${required_files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "ERROR: Required file $file was not generated"
            exit 1
          else
            echo "âœ“ $file exists"
          fi
        done

        # Check for broken internal links (basic check)
        echo "Checking for broken internal links..."
        python -c "
import re
import os
from pathlib import Path

def check_markdown_links(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Find markdown links
    links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
    broken = []

    for text, link in links:
        if link.startswith('http'):
            continue  # Skip external links
        if link.startswith('#'):
            continue  # Skip anchors for now

        # Check relative paths
        if link.startswith('./') or link.startswith('../'):
            target_path = (file_path.parent / link).resolve()
        else:
            target_path = Path('docs') / link

        if not target_path.exists():
            broken.append((text, link, str(target_path)))

    return broken

broken_links = []
for md_file in Path('docs').rglob('*.md'):
    broken = check_markdown_links(md_file)
    if broken:
        broken_links.extend([(str(md_file), link) for link in broken])

if broken_links:
    print('WARNING: Found potentially broken links:')
    for file, (text, link, target) in broken_links:
        print(f'  {file}: [{text}]({link}) -> {target}')
else:
    print('âœ“ No broken internal links found')
        "

    - name: Create documentation bundle
      run: |
        echo "Creating documentation bundle..."

        # Create a compressed archive of all documentation
        tar -czf capcat-docs-$(date +%Y%m%d-%H%M%S).tar.gz docs/

        # Create documentation manifest
        cat > docs/manifest.txt << EOF
Capcat Documentation Bundle
Generated: $(date -u)
Commit: ${{ github.sha }}
Branch: ${{ github.ref_name }}
Event: ${{ github.event_name }}

Contents:
$(find docs -type f -name "*.md" | sort)

Statistics:
- Total files: $(find docs -type f | wc -l)
- Markdown files: $(find docs -name "*.md" | wc -l)
- Total size: $(du -sh docs | cut -f1)
EOF

    - name: Deploy to GitHub Pages (main branch only)
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./docs
        destination_dir: .
        keep_files: false
        commit_message: |
          Deploy documentation (${{ github.sha }})

          Auto-generated from commit ${{ github.sha }}

          Changes:
          ${{ github.event.head_commit.message }}

    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v3
      with:
        name: capcat-documentation-${{ github.sha }}
        path: |
          docs/
          docs_*_report.txt
          capcat-docs-*.tar.gz
        retention-days: 30

    - name: Comment on PR with documentation preview
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');

          // Read documentation statistics
          let stats = {};
          try {
            stats = JSON.parse(fs.readFileSync('docs/stats.json', 'utf8'));
          } catch (e) {
            stats = { error: 'Could not read stats' };
          }

          // Create comment body
          const body = `## ðŸ“š Documentation Preview

          Documentation has been generated for this PR:

          ### ðŸ“Š Statistics
          - **Python files analyzed**: ${stats.python_files || 'N/A'}
          - **Documentation files generated**: ${stats.markdown_files || 'N/A'}
          - **Total lines of code**: ${stats.total_lines || 'N/A'}
          - **Documentation size**: ${stats.documentation_size_mb || 'N/A'} MB

          ### ðŸ“ Generated Documentation
          - [ðŸ“– Main Documentation](../actions/runs/${{ github.run_id }})
          - [ðŸ—ï¸ Architecture Diagrams](../actions/runs/${{ github.run_id }})
          - [ðŸ”§ API Reference](../actions/runs/${{ github.run_id }})
          - [ðŸ‘©â€ðŸ’» Developer Guide](../actions/runs/${{ github.run_id }})

          ### âœ… Validation Status
          - Code analysis: Completed
          - Link validation: Completed
          - File structure: Validated

          *Documentation generated at ${stats.generation_timestamp || new Date().toISOString()}*

          ---

          ðŸ“¥ Download the complete documentation bundle from the [workflow artifacts](../actions/runs/${{ github.run_id }}).
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });

  documentation-quality-check:
    runs-on: ubuntu-latest
    needs: generate-docs
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Download documentation artifacts
      uses: actions/download-artifact@v3
      with:
        name: capcat-documentation-${{ github.sha }}
        path: ./artifacts

    - name: Quality assessment
      run: |
        echo "Running documentation quality assessment..."

        # Check documentation completeness
        python -c "
import json
import os
from pathlib import Path

def assess_documentation_quality():
    docs_dir = Path('artifacts/docs')
    if not docs_dir.exists():
        print('ERROR: Documentation directory not found')
        return False

    # Check for required sections
    required_sections = [
        'README.md',
        'index.md',
        'api/README.md',
        'architecture/system.md',
        'developer/guide.md'
    ]

    missing_sections = []
    for section in required_sections:
        if not (docs_dir / section).exists():
            missing_sections.append(section)

    if missing_sections:
        print(f'WARNING: Missing documentation sections: {missing_sections}')
        quality_score = max(0, 100 - (len(missing_sections) * 20))
    else:
        quality_score = 100

    # Check file sizes (documentation should not be empty)
    empty_files = []
    for md_file in docs_dir.rglob('*.md'):
        if md_file.stat().st_size < 100:  # Less than 100 bytes
            empty_files.append(str(md_file.relative_to(docs_dir)))

    if empty_files:
        print(f'WARNING: Suspiciously small files: {empty_files}')
        quality_score -= len(empty_files) * 5

    print(f'Documentation Quality Score: {quality_score}/100')

    # Set GitHub output
    with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
        f.write(f'quality_score={quality_score}\n')
        f.write(f'missing_sections={\";\".join(missing_sections) if missing_sections else \"none\"}\n')
        f.write(f'empty_files={\";\".join(empty_files) if empty_files else \"none\"}\n')

    return quality_score >= 80

success = assess_documentation_quality()
exit(0 if success else 1)
        "

    - name: Comment quality assessment
      if: always()
      uses: actions/github-script@v6
      with:
        script: |
          const score = '${{ steps.quality-assessment.outputs.quality_score }}' || 'N/A';
          const missing = '${{ steps.quality-assessment.outputs.missing_sections }}' || 'none';
          const empty = '${{ steps.quality-assessment.outputs.empty_files }}' || 'none';

          let emoji = 'âœ…';
          let status = 'Excellent';

          if (score < 80) {
            emoji = 'âš ï¸';
            status = 'Needs Improvement';
          } else if (score < 90) {
            emoji = 'âœ…';
            status = 'Good';
          }

          const body = `## ${emoji} Documentation Quality Assessment

          **Overall Score**: ${score}/100 (${status})

          ### Issues Found
          - **Missing Sections**: ${missing === 'none' ? 'None' : missing.replace(/;/g, ', ')}
          - **Empty Files**: ${empty === 'none' ? 'None' : empty.replace(/;/g, ', ')}

          ### Recommendations
          ${score < 80 ? '- Please address missing sections and empty files before merging' : '- Documentation quality is acceptable'}
          ${missing !== 'none' ? '- Add the missing documentation sections' : ''}
          ${empty !== 'none' ? '- Review and populate empty documentation files' : ''}
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });